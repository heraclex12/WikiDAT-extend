
% Abstract
\centerline{\Large \textbf{Preface}}

\vspace{0.4in}

%\baselineskip=24pt
\linespread{1.6}

This document presents a gentle and accessible introduction to conduct quantitative
analyses with Wikipedia data. As you may know, Wikipedias in different languages are
independent from each other, hosting different communities (although some editors can
contrubute to different Wikipedia languages). In this context, three important
factors represent an unique opportunity for researchers to perform interesting 
studies in a wide variety of scientific disciplines.

\begin{itemize}
 \item The size of many Wikipedia communities, in some cases composed of millions 
of users (for the largest languages).
 \item The fact that we can find data for more than a decade of activity for many
available languages in Wikipedia.
 \item The precise level of detail of the records accounting for editorial and
administrative activities undertaken by community members.
\end{itemize}

A distinctive feature of this introductory guide is the focus on data retrieval 
and data preparation. Frequently, reports and papers about research works on data 
analysis explain in great detail numerical 
and graphical results, models and conclusions. However, in many cases little 
attention is paid to the description of which data sources were used, 
how these data were prepared before the analysis and additional 
information to facilitate the extension of the analysis in future studies. This is rather
unfortunate since, in general, data retrieval and data preparation usually consumes
no less than 75\% of the whole time devoted to quantitative analysis, specially
in very large datasets such as those found in Wikipedia. As a result, researchers 
and other stakeholders potentially insterested in Wikipedia data analysis, 
specially those without previous experience in this project, may become dissapointed, 
frustrated or discouraged in their attempt to replicate or extend previous work, 
or to develop their own studies. 

The first part of this guide covers all these important aspects in depth, providing
detailed descriptions of available data sources in Wikipedia, along with practical
methods and tools to prepare these data for the analysis. It also presents an
overview of useful existing tools and frameworks to make this process easier, automating
certain tasks whenever possible to minimize the chance of making mistakes and speed
up this time-consuming phase of the analysis. The second part 
includes a description of a general methodology to undertake quantitative
analysis with Wikipedia data, together with a collection of open source tools 
that researchers can use as building blocks to implement their own analyses. 
The third part introduces practical examples of quantiative analyses with Wikipedia
data. In every example, the main objectives are first introduced, followed
by the data and tools required to conduct the analysis. After this, the implementation
and results of the analysis are described, including code in SQL, Python and R to
carry out all necessary actions. Finally, all examples conclude with pointers to further
references and previous works for readers interested in learning further details.

I hope that this guide can help some researchers to enter the fascinating world
of Wikipedia research and data analysis, discovering many available data sources
and practical methodologies, so that they can bring in their valuable expertise and
knowledge to improve our understanding about how Wikipedia works and what we can
do to ensure its continuity for years to come.

\linespread{1.2}